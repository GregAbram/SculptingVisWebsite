<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Research Projects | Sculpting Visualizations</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="https://necolas.github.io/normalize.css/8.0.1/normalize.css">
        <link rel="stylesheet" href="css/style.css">
        <script src="js/code.js"></script>
        <style>
        sstrong {
          font-weight: bolder
        }
        </style>
    </head>
    <body>
      <navigation-bar>
        {% include "njk/header.html" %}
      </navigation-bar>

      <thrust-page>

        <thrust-sidebar>
          <div>
              <h1>Visualization Software Architectures for Arts, Humanities,
                  <br>and STEM Integration</h1>
              <h2>AR, VR, Physicalization, <br>& Interaction</h2>
              <ul>
                  <li><a href="#overview">AR, VR, Physicalization
                    <br>& Interaction</a></li>
                  <li><a href="#vr">Virtual Reality</a></li>
                  <li><a href="#ar">Augmented Reality</a></li>
                  <li><a href="#phys">Physicalization</a></li>
                  <li><a href="#interaction">Interaction</a></li>
                  <li><a href="#pubs">Publications</a></li>
              </ul>
          </div>
        </thrust-sidebar>

        <thrust-content>
          <div id="overview">
            <h2>AR, VR, Physicalization & Interaction</h2>
            <p class="big-paragraph">One of the Sculpting Vis Collaborative’s primary thrusts is the intersection of augemnted reality, virtual reality,
              physicalization, and interactivity. As computing capacity continues to advance, accessibility to big data is also improving. This broadens
              the potential for visualizations that move beyond two-dimensional screens and into the embodied, physical world. Significant research has
              demonstrated that tactile and three-dimensional visualizations improve memory, comprehension, and learning potential, especially in lay audiences.
              The Collaborative is working to explore these promising avenues for visualization through tightly integrated digital + analog methodologies.</p>
          <div class="single-image">
                <div class="first-image">
                    <img src="images/thrusts/VisSoftwareArch/Phys_teaser.png">
                </div>
            </div>
          </div>
          <div id="vr">
            <h2>Virtual Reality</h2>
            <p class="big-paragraph">The image below shows a demonstration at the Texas Advanced Computing Center’s Visualization of the use of virtual reality to view and
              explore a three-dimensional, multivairate visualization of the Gulf of Mexico, encoded using hand-crafted glyphs and colormaps in the
              Artifact-Based Rendering system. Here, PI Francesca Samsel and graduate student Claire Fitch assist Michael Dell as he explores the visualization
              in the VR headset.</p>
            <div class="single-image">
                <div class="first-image">
                    <img src="images/thrusts/VisSoftwareArch/VReh1.png">
                </div>
            </div>
          </div>
          <div id="ar">
            <h2>Augmented Reality</h2>
            <p class="big-paragraph">Physical visualizations, or physicalizations, are useful for many tasks such as communication and display, but are often insufficient
              as reserach tools without the addition of some sort of digital element. The Collaborative is therefore working to integrate augmented
              reality components with aspects of the physical world in order to broaden their potential for research-oriented use, such as data exploration,
              interrogation, and group science.</p>
            <div class="single-image">
                <div class="first-image">
                    <img src="images/thrusts/VisSoftwareArch/AR1.png">
                </div>
            </div>
          </div>
          <div id="phys">
            <h2>Physicalization</h2>
            <p class="big-paragraph">Incorporating physical components into reserach practice provides numerous benefits, including expanded avenues for bringing artists
              and members of the lay public directly into the visualization process. In the image below, on the upper left, artist Francesca Samsel sculpts
              glyphs out of clay. These clay glyphs can be scanned into the Artifact-Based Rendering system and used as data-mapped elements in visualizations.
              The bottom left image shows different types of soil collected from the Arctic as part of The Collaborative’s Climate Prisms project, which centered
              in part on bridging physical geographical changes and on-the-ground research processes with abstracted data for public consumption.
              The middle and rightmost images show glass pieces arranged on watercolor paper, created for use in a stop-motion animation to more clearly
              connect Arctic data with ice movement. The stop-motion will be used alongside climate data visualizations of Arctic icemelt. Physical objects
              provide opportunities to integrate artistic practice with research praxis and visualization production.</p>
            <div class="single-image">
                <div class="first-image">
                    <img src="images/thrusts/VisSoftwareArch/physicalization9.png">
                </div>
            </div>
          </div>
          <div id="interaction">
            <h2>Interaction</h2>
          <p class="big-paragraph">Data physicalizations (3D printed terrain models, anatomical scans, or even abstract data) can naturally engage both the
              visual and haptic senses in ways that are difficult or impossible to do with traditional planar touch screens and even immersive
              digital displays. Yet, the rigid 3D physicalizations produced with today’smost common 3D printers are fundamentally limited for data
              exploration and querying tasks that require dynamic input (e.g., touch sensing) and output (e.g., animation), functions that are easily handled
              with digital displays. We introduce a novel style of hybrid virtual + physical visualization designed specifically to support interactive data
              exploration tasks. Working toward a “best of both worlds”solution, our approach fuses immersive AR, physical 3D data printouts, and touch
              sensing through the physicalization. We demonstrate that this solution can support three of the most common spatial data querying interactions
              used in scientific visualization (streamline seeding, dynamic cutting places, and world-in-miniature visualization). Finally, wepresent quantitative
              performance data and describe a first application to exploratory visualization of an actively studied supercomputer climate simulation data with feedback
              from domain scientists.</p>
            <div class="single-image">
                <div class="first-image">
                    <img src="images/thrusts/VisSoftwareArch/Interactive1.png">
                </div>
            </div>
          </div>
          <div class=project-publications id=pubs>
            <h2>Publications</h2>
            <pubs>
              {% include "html/publications/2021/Multi-Touch/pub.html" %}
            </pubs>
          </div>
        </thrust-content>

        <thrust-footer>
          {% include "njk/footer.html" %}
        </thrust-footer>

      </thrust-page>
    </body>
</html>
